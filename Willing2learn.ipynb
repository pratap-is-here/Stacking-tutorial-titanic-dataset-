{"cells":[{"metadata":{"_uuid":"608dd3d863f02e18d2e490ae8d7b110b3115b1cb","scrolled":true,"trusted":true},"cell_type":"code","source":"# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\n%matplotlib inline\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for the stacking\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n                              GradientBoostingClassifier, ExtraTreesClassifier)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import KFold\nimport os\nprint(os.listdir(\"../input\"))\n#path=\"E:\\surya\\work\\kaggle titanic dataset\"\n#os.chdir(path)\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"output_type":"stream","text":"['test.csv', 'train.csv', 'gender_submission.csv']\n","name":"stdout"}]},{"metadata":{"_uuid":"bbb223c89aefd9ebc18cbcc86a6ed37aa5189488","trusted":true},"cell_type":"code","source":"print (os.listdir(os.getcwd()))","execution_count":2,"outputs":[{"output_type":"stream","text":"['__notebook_source__.ipynb', '.ipynb_checkpoints']\n","name":"stdout"}]},{"metadata":{"_uuid":"b995ee37e2a934659c51eda42bddb4a3792f48de","trusted":true},"cell_type":"code","source":"#Step 1: Dataset Exploration","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"d9e5bcb9c74b37875b6dab55c5b3176a869e447d","trusted":true},"cell_type":"code","source":"print (\"\\ntotal number of datapoints : 891\")\nprint (\"\\nnumber of useful features available : 9\")\nprint (\"\\nname of the passenger is not used as a feature.\")\nprint (\"\\ncabin number has many missing values\")","execution_count":4,"outputs":[{"output_type":"stream","text":"\ntotal number of datapoints : 891\n\nnumber of useful features available : 9\n\nname of the passenger is not used as a feature.\n\ncabin number has many missing values\n","name":"stdout"}]},{"metadata":{"_uuid":"78e2893bd96017b18014867e469a46d6ffd99b0d","trusted":true},"cell_type":"code","source":"#reading training dataset\nfeature_list=['PassengerId','Pclass','Name','Sex', 'Age','SibSp','Parch',\n                                                   'Ticket','Fare','Cabin','Embarked']\ndf_train_features=pd.read_csv(\"../input/train.csv\",usecols=feature_list)\ndf_train_labels=pd.read_csv(\"../input/train.csv\",usecols=['Survived'])\n\ndf_test_features=pd.read_csv(\"../input/test.csv\",usecols=feature_list)","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"fae7297598724610b6589048ba6922f80cf17a1b","scrolled":true,"trusted":true},"cell_type":"code","source":"df_train_features.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"   PassengerId  Pclass   ...    Cabin Embarked\n0            1       3   ...      NaN        S\n1            2       1   ...      C85        C\n2            3       3   ...      NaN        S\n3            4       1   ...     C123        S\n4            5       3   ...      NaN        S\n\n[5 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"7f0ba017d402a15609f6c449f8da586b46488ac3","trusted":true},"cell_type":"code","source":"df_train_labels.head()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"   Survived\n0         0\n1         1\n2         1\n3         1\n4         0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_features.head()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"   PassengerId  Pclass   ...    Cabin Embarked\n0          892       3   ...      NaN        Q\n1          893       3   ...      NaN        S\n2          894       2   ...      NaN        Q\n3          895       3   ...      NaN        S\n4          896       3   ...      NaN        S\n\n[5 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>3</td>\n      <td>Kelly, Mr. James</td>\n      <td>male</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330911</td>\n      <td>7.8292</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>3</td>\n      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n      <td>female</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>363272</td>\n      <td>7.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>2</td>\n      <td>Myles, Mr. Thomas Francis</td>\n      <td>male</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>240276</td>\n      <td>9.6875</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>3</td>\n      <td>Wirz, Mr. Albert</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>315154</td>\n      <td>8.6625</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>3</td>\n      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3101298</td>\n      <td>12.2875</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"b8aa48edc563494b7dd5b89aed3a17998f9a5dfc","trusted":true},"cell_type":"code","source":"#DATA PRE-PROCESSING\n\n#replacing 'male' with 1 and 'female' with 0 in the 'sex' column\ndf_train_features=df_train_features.replace('male',1)\ndf_train_features=df_train_features.replace('female',0)\n\ndf_test_features=df_test_features.replace('male',1)\ndf_test_features=df_test_features.replace('female',0)\n\n#extracting the numerical part of the ticket number\n#c=5\nfor s in df_train_features.iloc[:,7]:\n    if isinstance(s,str):\n        value=[int(s) for s in s.split(' ') if s.isdigit()]\n        if (len(value)!=0):\n            tktnum=value[0]\n        else:\n            tktnum=-1\n        #if (c>0):\n          #  c-=1\n        df_train_features=df_train_features.replace(s,tktnum)\n        #df_test_features=df_test_features.replace(s,tktnum)\n        \n#c=5\nfor s in df_test_features.iloc[:,7]:\n    if isinstance(s,str):\n        value=[int(s) for s in s.split(' ') if s.isdigit()]\n        if (len(value)!=0):\n            tktnum=value[0]\n        else:\n            tktnum=-1\n        #if (c>0):\n           # c-=1\n        #df_train_features=df_train_features.replace(s,tktnum)\n        df_test_features=df_test_features.replace(s,tktnum)\n\n#In 'embarked' column, replacing 'S' by 1,'C' by 2 and 'Q' by 3\ndf_train_features['Embarked'] = df_train_features['Embarked'].replace({\"S\":1.0,\"C\":2.0,\"Q\":3.0})\ndf_test_features['Embarked'] = df_test_features['Embarked'].replace({\"S\":1.0,\"C\":2.0,\"Q\":3.0})\n\n#Extracting only the surnames\nfor s in df_train_features.iloc[:,2]:\n    if (len(s)!=0):\n        value=[s for s in s.split(',')]\n        surname=value[0]\n    df_train_features=df_train_features.replace(s,surname)\n    df_test_features=df_test_features.replace(s,surname)\n\n#finding the list of unique surnames present and assigning them a numerical value\nls=df_train_features.Name.unique()\ndf_train_features=df_train_features.replace(ls,range(len(ls)))\nls=df_test_features.Name.unique()\ndf_test_features=df_test_features.replace(ls,range(len(ls)))\n\n#For cases where a passenger has more than one cabin number, extra features will be added. \n#If a person has two cabins, then 4 features will be added. 2 for alpha. part and 2 for numerical part.    \n#splitting cabin number in two parts: cabin1 : contains the alphabetical part and cabin2 : contains the numerical part\n\n#first let us find the maximum number of cabins a passenger has.\nMax=0\nfor s in df_train_features.iloc[:,9]:\n    if isinstance(s,str):\n        value=[s for s in s.split(' ')]\n        if (Max<len(value)):\n            Max=len(value)\nprint ('maximum number of cabins a passenger has : ',Max)\n\n#now let us add the required number of features with default values for each row. Later on the value of a row will be changed as \n#'needed'\nx=range(Max)\nfor i in x:\n    df_train_features.loc[:,'ap'+str(i)]=-1\n    df_train_features.loc[:,'np'+str(i)]=-1\n    df_test_features.loc[:,'ap'+str(i)]=-1\n    df_test_features.loc[:,'np'+str(i)]=-1\n    feature_list.append('ap'+str(i))\n    feature_list.append('np'+str(i))\n#now let us fill in the apprpriate values in these new columns\nap=11\nnp=12\nrowin=0\n\nfor s in df_train_features.iloc[:,9]:\n    if isinstance(s,str):\n        #print (s)\n        #print (type(s))\n        value=[s for s in s.split(' ')]\n        for cn in value:\n            #print (cn[0])\n            #print (cn[1:])\n            #print (ap)\n            df_train_features.iloc[rowin,ap]=ord(cn[0])\n            #df_test_features.iloc[rowin,ap]=ord(cn[0])\n            if (cn[1:]!=''):\n                df_train_features.iloc[rowin,np]=int(cn[1:])\n                #df_test_features.iloc[rowin,np]=int(cn[1:])\n            else:\n                df_train_features.iloc[rowin,np]=-1\n                #df_test_features.iloc[rowin,np]=-1\n            ap+=2\n            np+=2\n    ap=11\n    np=12\n    rowin+=1\n\nap=11\nnp=12\nrowin=0\n    \nfor s in df_test_features.iloc[:,9]:\n    if isinstance(s,str):\n        #print (s)\n        #print (type(s))\n        value=[s for s in s.split(' ')]\n        for cn in value:\n            #print (cn[0])\n            #print (cn[1:])\n            #print (ap)\n            #df_train_features.iloc[rowin,ap]=ord(cn[0])\n            df_test_features.iloc[rowin,ap]=ord(cn[0])\n            if (cn[1:]!=''):\n                #df_train_features.iloc[rowin,np]=int(cn[1:])\n                df_test_features.iloc[rowin,np]=int(cn[1:])\n            else:\n                #df_train_features.iloc[rowin,np]=-1\n                df_test_features.iloc[rowin,np]=-1\n            ap+=2\n            np+=2\n    ap=11\n    np=12\n    rowin+=1\n    \n            \n#finally removing the original 'cabin' column\ndf_train_features=df_train_features.drop(columns=['Cabin'])\ndf_test_features=df_test_features.drop(columns=['Cabin'])\n#removing from features list as well\ndel feature_list[feature_list.index('Cabin')]\n\n#replacing all the missing values in age column by mean age\nmean_age=df_train_features['Age'].mean()\ndf_train_features['Age']=df_train_features['Age'].fillna(mean_age)\ndf_test_features['Age']=df_test_features['Age'].fillna(mean_age)\n\n#there are two nan values present in 'Embarked' column. we are replacing it with median value\nmedian=df_train_features['Embarked'].median()\ndf_train_features['Embarked']=df_train_features['Embarked'].fillna(median)\ndf_test_features['Embarked']=df_test_features['Embarked'].fillna(median)\n\n\n#checking for any NAN values left\nl=[]\nfor i in feature_list:\n    x=df_test_features[i].isnull().sum().sum()\n    if x>0:\n        print (x)\n        l.append(i)\nfor i in l:\n    print (i)","execution_count":9,"outputs":[{"output_type":"stream","text":"maximum number of cabins a passenger has :  4\n1\nFare\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_fare=df_test_features['Fare'].mean()\ndf_test_features['Fare']=df_test_features['Fare'].fillna(avg_fare)","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"20a7f24c94285be97ad554b652ddd5e52b2a3407","scrolled":true,"trusted":true},"cell_type":"code","source":"df_train_features.head()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"   PassengerId  Pclass  Name  Sex   Age ...   np1  ap2  np2  ap3  np3\n0            1       3     0    1  22.0 ...    -1   -1   -1   -1   -1\n1            2       1     1    0  38.0 ...    -1   -1   -1   -1   -1\n2            3       3     2    0  26.0 ...    -1   -1   -1   -1   -1\n3            4       1     3    0  35.0 ...    -1   -1   -1   -1   -1\n4            5       3     4    1  35.0 ...    -1   -1   -1   -1   -1\n\n[5 rows x 18 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>ap0</th>\n      <th>np0</th>\n      <th>ap1</th>\n      <th>np1</th>\n      <th>ap2</th>\n      <th>np2</th>\n      <th>ap3</th>\n      <th>np3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>21171</td>\n      <td>7.2500</td>\n      <td>1.0</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>17599</td>\n      <td>71.2833</td>\n      <td>2.0</td>\n      <td>67</td>\n      <td>85</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3101282</td>\n      <td>7.9250</td>\n      <td>1.0</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>1.0</td>\n      <td>67</td>\n      <td>123</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>1.0</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_features.head()","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"   PassengerId  Pclass  Name  Sex   Age ...   np1  ap2  np2  ap3  np3\n0          892       3     0    1  34.5 ...    -1   -1   -1   -1   -1\n1          893       3     1    0  47.0 ...    -1   -1   -1   -1   -1\n2          894       2     2    1  62.0 ...    -1   -1   -1   -1   -1\n3          895       3     3    1  27.0 ...    -1   -1   -1   -1   -1\n4          896       3     4    0  22.0 ...    -1   -1   -1   -1   -1\n\n[5 rows x 18 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>ap0</th>\n      <th>np0</th>\n      <th>ap1</th>\n      <th>np1</th>\n      <th>ap2</th>\n      <th>np2</th>\n      <th>ap3</th>\n      <th>np3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330911</td>\n      <td>7.8292</td>\n      <td>3.0</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>363272</td>\n      <td>7.0000</td>\n      <td>1.0</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>240276</td>\n      <td>9.6875</td>\n      <td>3.0</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>315154</td>\n      <td>8.6625</td>\n      <td>1.0</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>3</td>\n      <td>4</td>\n      <td>0</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3101298</td>\n      <td>12.2875</td>\n      <td>1.0</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"ab45e08be945e1682e41e9da41887ff59c5d7a21","trusted":true},"cell_type":"code","source":"#Converting dataframe to numpy arrays for further use\nX=df_train_features.values\ny=df_train_labels.values\nX_test=df_test_features.values\n\nprint ('X.shape = %s' % str(X.shape))\nprint ('y.shape = %s' % str(y.shape))\nprint ('X_test.shape = %s' % str(X_test.shape))","execution_count":13,"outputs":[{"output_type":"stream","text":"X.shape = (891, 18)\ny.shape = (891, 1)\nX_test.shape = (418, 18)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"array([[  1.,   3.,   0., ...,  -1.,  -1.,  -1.],\n       [  2.,   1.,   1., ...,  -1.,  -1.,  -1.],\n       [  3.,   3.,   2., ...,  -1.,  -1.,  -1.],\n       ...,\n       [889.,   3., 604., ...,  -1.,  -1.,  -1.],\n       [890.,   1., 665., ...,  -1.,  -1.,  -1.],\n       [891.,   3., 666., ...,  -1.,  -1.,  -1.]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"array([[ 8.920e+02,  3.000e+00,  0.000e+00, ..., -1.000e+00, -1.000e+00,\n        -1.000e+00],\n       [ 8.930e+02,  3.000e+00,  1.000e+00, ..., -1.000e+00, -1.000e+00,\n        -1.000e+00],\n       [ 8.940e+02,  2.000e+00,  2.000e+00, ..., -1.000e+00, -1.000e+00,\n        -1.000e+00],\n       ...,\n       [ 1.307e+03,  3.000e+00,  4.150e+02, ..., -1.000e+00, -1.000e+00,\n        -1.000e+00],\n       [ 1.308e+03,  3.000e+00,  4.160e+02, ..., -1.000e+00, -1.000e+00,\n        -1.000e+00],\n       [ 1.309e+03,  3.000e+00,  4.170e+02, ..., -1.000e+00, -1.000e+00,\n        -1.000e+00]])"},"metadata":{}}]},{"metadata":{"_uuid":"e4b71080e5078ad737735be50a8f0f93401855a2","trusted":true},"cell_type":"code","source":"#Step 2: OPTIMIZE FEATURE SELECTION/ENGINEERING","execution_count":16,"outputs":[]},{"metadata":{"_uuid":"77a207ea828fcd9d4bb5f4393614baa7b3c197ab","trusted":true},"cell_type":"code","source":"#First, let us do feature scalling so that no feature gets more importance simply based on it's numerical value\n#feature scalling\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\nX=scaler.fit_transform(X)\n\n\n#scaler=MinMaxScaler()\nX_test=scaler.fit_transform(X_test)\n\n","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"b9bdab4a9c7cf6b02ca8a6b142878074b37309fb","scrolled":true,"trusted":true},"cell_type":"code","source":"X[0:5]","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"array([[0.        , 1.        , 0.        , 1.        , 0.27117366,\n        0.125     , 0.        , 0.00682677, 0.01415106, 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.0011236 , 0.        , 0.0015015 , 0.        , 0.4722292 ,\n        0.125     , 0.        , 0.00567501, 0.13913574, 0.5       ,\n        0.8       , 0.57718121, 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.00224719, 1.        , 0.003003  , 0.        , 0.32143755,\n        0.        , 0.        , 0.99998871, 0.01546857, 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.00337079, 0.        , 0.0045045 , 0.        , 0.43453129,\n        0.125     , 0.        , 0.03669537, 0.1036443 , 0.        ,\n        0.8       , 0.83221477, 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.00449438, 1.        , 0.00600601, 1.        , 0.43453129,\n        0.        , 0.        , 0.12041687, 0.01571255, 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test[0:5]","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"array([[0.        , 1.        , 0.        , 1.        , 0.4527232 ,\n        0.        , 0.        , 0.10669965, 0.01528158, 1.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.00239808, 1.        , 0.00239808, 0.        , 0.61756561,\n        0.125     , 0.        , 0.11713426, 0.01366309, 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.00479616, 0.5       , 0.00479616, 1.        , 0.8153765 ,\n        0.        , 0.        , 0.07747493, 0.01890874, 1.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.00719424, 1.        , 0.00719424, 1.        , 0.35381775,\n        0.        , 0.        , 0.10161889, 0.01690807, 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.00959233, 1.        , 0.00959233, 0.        , 0.28788079,\n        0.125     , 0.11111111, 0.99999452, 0.0239836 , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ]])"},"metadata":{}}]},{"metadata":{"_uuid":"200e667dd47bda26c8e1e490cf45624325d0f6d1","scrolled":true,"trusted":true},"cell_type":"code","source":"print (y[:5])","execution_count":20,"outputs":[{"output_type":"stream","text":"[[0]\n [1]\n [1]\n [1]\n [0]]\n","name":"stdout"}]},{"metadata":{"_uuid":"98d541d042a0a959ca3f24f47ad039553857e4a4","trusted":true},"cell_type":"code","source":"len(y)","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"891"},"metadata":{}}]},{"metadata":{"_uuid":"85c8b6b7722c805c8e15fb8b36b321870e1cabc7","scrolled":true,"trusted":true},"cell_type":"code","source":"new=[]\nfor i in y:\n    for j in i:\n        new.append(j)\nprint (new[:5])\ny=new","execution_count":22,"outputs":[{"output_type":"stream","text":"[0, 1, 1, 1, 0]\n","name":"stdout"}]},{"metadata":{"_uuid":"f03e7415d1eb33f5e186704ba4f971ce552b65d3","scrolled":true,"trusted":true},"cell_type":"code","source":"#now let us find the importance of all features using selectkpercentile\nfrom sklearn.feature_selection import SelectPercentile, f_classif\nselector = SelectPercentile(f_classif, percentile=80)#highest accuracy .80 (approx.) from decision tree classifier\n#                                                                                                   at this percentile\nselector.fit(X,y)\nX_new=selector.transform(X)\nprint ('shape of X_new ',X_new.shape)\ntry:\n    X_points = range(X.shape[1])\nexcept IndexError:\n    X_points = 1\n    \n\n#using previously selected features\nX_test=selector.transform(X_test)\nprint ('X_test.shape = %s ' % str(X_test.shape))\n'''\ntry:\n    X_points = range(X_test.shape[1])\nexcept IndexError:\n    X_points = 1\n'''    ","execution_count":23,"outputs":[{"output_type":"stream","text":"shape of X_new  (891, 14)\nX_test.shape = (418, 14) \n","name":"stdout"},{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"'\\ntry:\\n    X_points = range(X_test.shape[1])\\nexcept IndexError:\\n    X_points = 1\\n'"},"metadata":{}}]},{"metadata":{"_uuid":"991333078d4b5b11ec3dec6b94da781304a3ad23","trusted":true},"cell_type":"code","source":"#checking out the scores of the features\nscore=selector.scores_.tolist()\nnames=list(df_train_features)\nnew=zip(names,score)\nfor i in new:\n    print (i[0],\" score = {:8.2f}\".format(i[1]))","execution_count":24,"outputs":[{"output_type":"stream","text":"PassengerId  score =     0.02\nPclass  score =   115.03\nName  score =     0.27\nSex  score =   372.41\nAge  score =     4.35\nSibSp  score =     1.11\nParch  score =     5.96\nTicket  score =     8.20\nFare  score =    63.03\nEmbarked  score =    10.26\nap0  score =    98.85\nnp0  score =    53.15\nap1  score =     3.97\nnp1  score =     4.91\nap2  score =     1.97\nnp2  score =     2.67\nap3  score =     3.22\nnp3  score =     3.22\n","name":"stdout"}]},{"metadata":{"_uuid":"c763fb72a36a7c549cfa1f4a755570e64ac3407c","trusted":true},"cell_type":"code","source":"plt.bar(X_points , selector.scores_, width=.2,\n        label=r'Univariate score ($-Log(p_{value})$)', color='darkorange',\n        edgecolor='black')","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"<BarContainer object of 18 artists>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"_uuid":"2424255720f5c1443c648f4c85cd1ed1942c61ab","trusted":true},"cell_type":"code","source":"#STEP 3:Trying out a variety of classifiers and tuning them as well ","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting data into training and testing set\nfrom sklearn.model_selection import train_test_split\nfeatures_train, features_test, labels_train, labels_test = train_test_split(X_new, y, test_size=0.30, random_state=42)\n","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_folds = 5\nn_trees = 50\n\n#level 0 classifiers\n'''\nclfs = [\n    RandomForestClassifier(n_estimators = n_trees, criterion = 'gini', n_jobs = -1, warm_start = True, max_depth=5, min_samples_leaf=2,max_features='sqrt'),\n    ExtraTreesClassifier(n_jobs=-1,n_estimators = n_trees, criterion = 'gini', max_depth=5, min_samples_leaf=3),\n    GradientBoostingClassifier(n_estimators = n_trees, max_depth = 5, min_samples_leaf= 3),\n    AdaBoostClassifier(n_estimators = int(n_trees/2), learning_rate = 0.95),\n    xgb.XGBClassifier(),\n    SVC(),\n    sklearn.tree.DecisionTreeClassifier()\n]'''\nfrom sklearn.naive_bayes import GaussianNB\nclfs = [\n    RandomForestClassifier(n_estimators = n_trees, criterion = 'gini'),\n    ExtraTreesClassifier(n_estimators = n_trees, criterion = 'gini'),\n    GradientBoostingClassifier(n_estimators = n_trees),\n    AdaBoostClassifier(n_estimators = int(n_trees/2)),\n    xgb.XGBClassifier(),\n    #SVC(),\n    #sklearn.tree.DecisionTreeClassifier(),\n    #sklearn.linear_model.Perceptron(tol=1e-3, random_state=0),\n    #GaussianNB(),\n    #sklearn.linear_model.LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial'),\n    #sklearn.neighbors.KNeighborsClassifier(n_neighbors=3)\n    \n]","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#first training and testing on the train.csv data only\n \ndef run(features_train, labels_train, features_test, clfs, n_folds = 5, labels_test = None, submission = False):\n    import numpy as np\n    # Ready for cross validation\n    skfold = StratifiedKFold(n_splits=n_folds)\n    skf = list(skfold.split(features_train, labels_train))\n   \n    # Pre-allocate the stacked dataset\n    blend_train = np.zeros((features_train.shape[0], len(clfs))) # Number of training data x Number of classifiers\n    blend_test = np.zeros((features_test.shape[0], len(clfs))) # Number of testing data x Number of classifiers\n    \n    if(submission == True):\n        print(\"\\nThis run is on entire training dataset and we will create a submission file in this run. :)\")\n\n    print ('\\nfeatures_train.shape = %s' % (str(features_train.shape)))\n    print ('features_test.shape = %s' % (str(features_test.shape)))\n    print ('blend_train.shape = %s' % (str(blend_train.shape)))\n    print ('blend_test.shape = %s' % (str(blend_test.shape)))\n\n    # For each classifier, we train the number of fold times (=n_folds)\n    for j, clf in enumerate(clfs):\n        print (\"\\n#####################################################\")\n        print ('\\nTraining classifier [%s]' % (str(j)))\n        blend_test_j = np.zeros((features_test.shape[0], len(skf)))\n        for i, (train_index, cv_index) in enumerate(skf):\n            print ('Fold [%s]' % (str(i)))\n        \n            # This is the training and validation set\n            #print (\"train_index\",train_index)\n            X_train = features_train[train_index]\n            Y_train = np.array(labels_train)[train_index]\n            X_cv = features_train[cv_index]\n            Y_cv = np.array(labels_train)[cv_index]\n        \n            clf.fit(X_train, Y_train)\n        \n            # This output will be the basis for our blended classifier to train against,\n            # which is also the output of our classifiers\n            blend_train[cv_index, j] = clf.predict(X_cv)\n            blend_test_j[:, i] = clf.predict(features_test)\n        \n        # Take the mean of the predictions of the cross validation set\n        blend_test[:, j] = blend_test_j.mean(1)\n        pred = blend_test[:, j]\n        #print (pred[0:5])\n        #print (labels_test[0:5])\n        pred[(pred >= 0.5)] = 1\n        pred[(pred < 0.5)] = 0\n        #print (pred[0:5])\n        if (submission == False):\n            \n            print (\"accuracy_score : \",accuracy_score(labels_test,pred))\n            print ('precision : ',precision_score(labels_test,pred))\n            print ('recall : ',recall_score(labels_test,pred))\n    \n    \n    \n    \n\n    print ('\\nlen(labels_train) = %s' % (str(len(labels_train))))\n\n    # Start blending!\n    bclf = SVC( kernel = 'linear', C = 0.025)\n    bclf.fit(blend_train, labels_train)\n\n    # Predict now\n    Y_test_predict = bclf.predict(blend_test)\n    if (submission == False):\n        \n        print (\"\\naccuracy_score : \",accuracy_score(labels_test,Y_test_predict))\n        print ('precision : ',precision_score(labels_test,Y_test_predict))\n        print ('recall : ',recall_score(labels_test,Y_test_predict))\n    \n    if (submission == True):\n        x =range(892,1310)\n        #creating the submission file\n        submission=pd.DataFrame({'PassengerId':x,'Survived':Y_test_predict})\n        print (submission.head())\n        submission.to_csv(path_or_buf='submission.csv',index=False)\n        \n    print (\"===========================================================================================================================\")\n    \nrun(features_train, labels_train, features_test, clfs, n_folds, labels_test)\n\n# now, we train our model on complete data from train.csv file and test on data from test.csv file before we make our submission\nrun(X_new, y, X_test, clfs, n_folds, submission = True)","execution_count":29,"outputs":[{"output_type":"stream","text":"\nfeatures_train.shape = (623, 14)\nfeatures_test.shape = (268, 14)\nblend_train.shape = (623, 5)\nblend_test.shape = (268, 5)\n\n#####################################################\n\nTraining classifier [0]\nFold [0]\nFold [1]\nFold [2]\nFold [3]\nFold [4]\naccuracy_score :  0.7947761194029851\nprecision :  0.7978723404255319\nrecall :  0.6756756756756757\n\n#####################################################\n\nTraining classifier [1]\nFold [0]\nFold [1]\nFold [2]\nFold [3]\nFold [4]\naccuracy_score :  0.7985074626865671\nprecision :  0.8\nrecall :  0.6846846846846847\n\n#####################################################\n\nTraining classifier [2]\nFold [0]\nFold [1]\nFold [2]\nFold [3]\nFold [4]\naccuracy_score :  0.8208955223880597\nprecision :  0.8705882352941177\nrecall :  0.6666666666666666\n\n#####################################################\n\nTraining classifier [3]\nFold [0]\nFold [1]\nFold [2]\nFold [3]\nFold [4]\naccuracy_score :  0.8059701492537313\nprecision :  0.7920792079207921\nrecall :  0.7207207207207207\n\n#####################################################\n\nTraining classifier [4]\nFold [0]\nFold [1]\nFold [2]\nFold [3]\nFold [4]\naccuracy_score :  0.8208955223880597\nprecision :  0.8620689655172413\nrecall :  0.6756756756756757\n\nlen(labels_train) = 623\n\naccuracy_score :  0.8134328358208955\nprecision :  0.8351648351648352\nrecall :  0.6846846846846847\n===========================================================================================================================\n\nThis run is on entire training dataset and we will create a submission file in this run. :)\n\nfeatures_train.shape = (891, 14)\nfeatures_test.shape = (418, 14)\nblend_train.shape = (891, 5)\nblend_test.shape = (418, 5)\n\n#####################################################\n\nTraining classifier [0]\nFold [0]\nFold [1]\nFold [2]\nFold [3]\nFold [4]\n\n#####################################################\n\nTraining classifier [1]\nFold [0]\nFold [1]\nFold [2]\nFold [3]\nFold [4]\n\n#####################################################\n\nTraining classifier [2]\nFold [0]\nFold [1]\nFold [2]\nFold [3]\nFold [4]\n\n#####################################################\n\nTraining classifier [3]\nFold [0]\nFold [1]\nFold [2]\nFold [3]\nFold [4]\n\n#####################################################\n\nTraining classifier [4]\nFold [0]\nFold [1]\nFold [2]\nFold [3]\nFold [4]\n\nlen(labels_train) = 891\n   PassengerId  Survived\n0          892         0\n1          893         0\n2          894         0\n3          895         0\n4          896         1\n===========================================================================================================================\n","name":"stdout"}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}